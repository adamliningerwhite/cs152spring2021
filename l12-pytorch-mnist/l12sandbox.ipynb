{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from time import time\n",
    "from typing import Tuple, List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_loader(path: str, train: bool) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"Return an MNIST dataloader for all ten digits.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to store/find the MNIST dataset\n",
    "        train (bool): Load the training set if True, validation set if false\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Tensor, Tensor]: Return images and labels\n",
    "    \"\"\"\n",
    "\n",
    "    # All inputs must be converted into torch tensors, and the normalization values\n",
    "    # have been precomputed and provided below.\n",
    "    mnist_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)),]\n",
    "    )\n",
    "\n",
    "    # We'll use dataloader more later on, so I want you to get used to seeing them\n",
    "    dataset = MNIST(root=path, train=train, download=True, transform=mnist_transforms)\n",
    "    loader = DataLoader(dataset, batch_size=len(dataset))\n",
    "\n",
    "    # Grab all images and targets from the loader\n",
    "    images, targets = next(iter(loader))\n",
    "\n",
    "    # Reshape the images into row vectors (instead of 28 by 28 matrices)\n",
    "    m = images.shape[0]\n",
    "    images = images.view(m, -1)\n",
    "\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_data(path: str) -> Tuple[Tensor, Tensor, Tensor, Tensor]:\n",
    "    \"\"\"Return training and validation dataset images and labels.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to store/find the MNIST dataset\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Tensor, Tensor, Tensor, Tensor]: Training images and labels, then validation\n",
    "    \"\"\"\n",
    "    train_imgs, train_trgs = get_mnist_loader(path, train=True)\n",
    "    valid_imgs, valid_trgs = get_mnist_loader(path, train=False)\n",
    "\n",
    "    return train_imgs, train_trgs, valid_imgs, valid_trgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning(\n",
    "    train_costs: List[float], valid_costs: List[float], valid_accuracies: List[float]\n",
    "):\n",
    "    \"\"\"Plot learning process.\n",
    "\n",
    "    Args:\n",
    "        train_costs (List[float]): List of training costs\n",
    "        valid_costs (List[float]): List of validation costs\n",
    "        valid_accuracies (List[float]): List of validation accuracies\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    epochs = range(len(train_costs))\n",
    "\n",
    "    fig.suptitle(\"MNIST Training\")\n",
    "\n",
    "    axes[0].plot(epochs, train_costs)\n",
    "    axes[0].plot(epochs, valid_costs)\n",
    "    axes[0].legend((\"Training\", \"Validation\"))\n",
    "    axes[0].set_xlabel(\"Epoch\")\n",
    "    axes[0].set_ylabel(\"Cost\")\n",
    "\n",
    "    axes[1].plot(epochs, valid_accuracies)\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].set_ylabel(\"Accuracy\")\n",
    "    axes[1].set_ylim((0, 1))\n",
    "    axes[1].grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "source": [
    "mnist_dir = \"../data\"\n",
    "num_epochs = 10\n",
    "learning_rate = 0.1\n",
    "show_plot = False\n",
    "\n",
    "train_imgs, train_trgs, valid_imgs, valid_trgs = get_mnist_data(mnist_dir)\n",
    "\n",
    "nx = train_imgs.shape[1]\n",
    "ny = train_trgs.unique().shape[0]\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: (DO THIS LAST)try adding additional layers, but make certain\n",
    "# that the final layer is a Linear layer with out_features=ny.\n",
    "model = torch.nn.Sequential(torch.nn.Linear(in_features=nx, out_features=ny),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a CrossEntropyLoss function by looking at the documentation here:\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 0/10 -> T Cost: 0.627, V Cost: 0.610, V Accuracy: 0.822   (0.198s)\n",
      " 1/10 -> T Cost: 0.587, V Cost: 0.568, V Accuracy: 0.840   (0.275s)\n",
      " 2/10 -> T Cost: 0.564, V Cost: 0.546, V Accuracy: 0.855   (0.132s)\n",
      " 3/10 -> T Cost: 0.541, V Cost: 0.521, V Accuracy: 0.862   (0.096s)\n",
      " 4/10 -> T Cost: 0.525, V Cost: 0.506, V Accuracy: 0.868   (0.097s)\n",
      " 5/10 -> T Cost: 0.511, V Cost: 0.492, V Accuracy: 0.873   (0.085s)\n",
      " 6/10 -> T Cost: 0.500, V Cost: 0.481, V Accuracy: 0.876   (0.105s)\n",
      " 7/10 -> T Cost: 0.491, V Cost: 0.471, V Accuracy: 0.877   (0.085s)\n",
      " 8/10 -> T Cost: 0.483, V Cost: 0.464, V Accuracy: 0.880   (0.084s)\n",
      " 9/10 -> T Cost: 0.476, V Cost: 0.456, V Accuracy: 0.882   (0.112s)\n"
     ]
    }
   ],
   "source": [
    "train_costs = []\n",
    "valid_costs = []\n",
    "valid_accus = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    epoch_start = time()\n",
    "\n",
    "    # Put the model into training mode\n",
    "    model.train()\n",
    "\n",
    "    # Forward (compute the neural network output)\n",
    "    # TODO: compute the outputs of the neural network model\n",
    "    train_yhat = model(train_imgs)\n",
    "\n",
    "    # Compute cost (average loss over all examples)\n",
    "    train_cost = cross_entropy_loss(train_yhat, train_trgs)\n",
    "\n",
    "    # Compute accuracy on validation data\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_yhat = model(valid_imgs)\n",
    "        valid_cost = cross_entropy_loss(valid_yhat, valid_trgs)\n",
    "        predictions = valid_yhat.argmax(dim=1, keepdim=True)\n",
    "        valid_accuracy = predictions.eq(valid_trgs.view_as(predictions))\n",
    "\n",
    "        # Convert correct/incorrect matrix into a percentage\n",
    "        valid_accuracy = valid_accuracy.double().mean().item()\n",
    "\n",
    "    # Create message to print\n",
    "    num_digits = len(str(num_epochs))\n",
    "    msg = f\"{epoch:>{num_digits}}/{num_epochs}\"\n",
    "    msg += f\" -> T Cost: {train_cost:.3f}\"\n",
    "    msg += f\", V Cost: {valid_cost:.3f}\"\n",
    "    msg += f\", V Accuracy: {valid_accuracy:.3f}\"\n",
    "\n",
    "    # Put the model into training mode\n",
    "    model.train()\n",
    "\n",
    "    # Backward (compute gradients)\n",
    "    # TODO: In two steps, zero out the model gradients and compute new gradients\n",
    "    model.zero_grad()\n",
    "    train_cost.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            # TODO: update the model parameters\n",
    "            param -= learning_rate * param.grad\n",
    "\n",
    "    print(msg, f\"  ({time() - epoch_start:.3f}s)\")\n",
    "\n",
    "    train_costs.append(train_cost)\n",
    "    valid_costs.append(valid_cost)\n",
    "    valid_accus.append(valid_accuracy)\n",
    "\n",
    "if show_plot:\n",
    "    plot_learning(train_costs, valid_costs, valid_accus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}