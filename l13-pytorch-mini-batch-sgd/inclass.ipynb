{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-batch stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "num_epochs = 2\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34md\u001b[33mr\u001b[31mw\u001b[32mx\u001b[0m\u001b[33mr\u001b[38;5;244m-\u001b[32mx\u001b[33mr\u001b[38;5;244m-\u001b[32mx\u001b[0m@ \u001b[38;5;244m-\u001b[0m \u001b[1;33majcd2020\u001b[0m \u001b[34m 7 Feb 15:39\u001b[0m \u001b[1;34mMNIST\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5,), (5, 2), 5)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5,), (5, 2), (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "?torchvision.transforms.Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]),\n",
       " torch.Size([60000]),\n",
       " torch.Size([10000, 28, 28]),\n",
       " torch.Size([10000]))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../data/\"\n",
    "\n",
    "mnist_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root=data_path, train=True, download=True, transform=mnist_transforms\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "valid_data = torchvision.datasets.MNIST(\n",
    "    root=data_path, train=False, transform=mnist_transforms\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=len(valid_data))\n",
    "\n",
    "train_data.data.shape, train_data.targets.shape, valid_data.data.shape, valid_data.targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 5)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].shape, train_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f82a192dd00>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(train_data[0][0].squeeze())\n",
    "\n",
    "# train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 28, 28]) torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    \n",
    "    print(images.shape, labels.shape)\n",
    "    \n",
    "    first_image_in_batch = images[0]\n",
    "    \n",
    "    plt.imshow(first_image_in_batch.squeeze())\n",
    "    plt.title(labels[0].item(), fontsize=32)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 28 * 28\n",
    "ny = 10\n",
    "\n",
    "# Why should we have 10 outputs neurons? Why not 1?\n",
    "# It makes learning harder.\n",
    "# A 1 is closer looking to a 7, but how do we make sure the loss\n",
    "# function indicates such a characteristic?\n",
    "\n",
    "# All parameters have requires_grad=True set\n",
    "model = torch.nn.Sequential(torch.nn.Linear(in_features=nx, out_features=ny))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the loss function (vs. cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this class\n",
    "# - loss is the error for a single training example\n",
    "# - cost is the average loss for all training examples in a batch\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implement mini-batch stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.056929349899292e-05 0.00015028257369995116 0.5464\n",
      "1 2.5438714027404785e-05 0.00011821191310882569 0.6481\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Loop\n",
    "#     compute network outputs\n",
    "#     compute loss\n",
    "#     compute derivatices\n",
    "#     update parameters\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Update the model parameters (weights and biases, for now...)\n",
    "    train_count = 0\n",
    "    train_cost = 0\n",
    "    for X, y in train_loader:\n",
    "        \n",
    "#         print(X.view(-1, nx).shape, y.shape)\n",
    "\n",
    "        # Compute network outputs\n",
    "        yhat = model(X.view(-1, nx))\n",
    "        \n",
    "        # Compute cost\n",
    "        cost = loss(yhat, y)\n",
    "        \n",
    "        # Compute gradients\n",
    "        model.zero_grad()\n",
    "        cost.backward()\n",
    "        \n",
    "        # Update paramters\n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                param -= learning_rate * param.grad\n",
    "        \n",
    "        train_count += X.shape[0]\n",
    "        train_cost += cost.item()\n",
    "    \n",
    "    \n",
    "    # Set model to evaluation/inference mode\n",
    "    model.eval()\n",
    "    \n",
    "    valid_count = 0\n",
    "    valid_cost = 0\n",
    "    valid_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in valid_loader:\n",
    "            \n",
    "            # Compute model\n",
    "            yhat = model(X.view(-1, nx))\n",
    "            cost = loss(yhat, y)\n",
    "            \n",
    "            # Convert model ouput into discrete predictions\n",
    "            predictions = yhat.argmax(dim=1, keepdim=True)\n",
    "            \n",
    "            # Compute the number of correct predictions\n",
    "            correct = predictions.eq(y.view_as(predictions)).double().sum().item()\n",
    "            \n",
    "            valid_count += X.shape[0]\n",
    "            valid_cost += cost.item()\n",
    "            valid_correct += correct\n",
    "    \n",
    "        \n",
    "    print(epoch, train_cost / train_count, valid_cost / valid_count, valid_correct / valid_count)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 1, 28, 28]), torch.Size([10000, 784]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.view(-1, 28*28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0, 0, :4, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "        -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.view(-1, 28*28)[0, :16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5454.545454545455"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60000/11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape[0] / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is mini-batch SGD doing better than batch GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simplified example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 1, 28, 28]) torch.Size([1024, 784])\n",
      "torch.Size([1024, 10]) torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Update the model parameters (weights and biases, for now...)\n",
    "    for X, y in train_loader:\n",
    "        \n",
    "        # Compute network outputs\n",
    "        \n",
    "        print(X.shape, X.view(-1, nx).shape)\n",
    "        \n",
    "        yhat = model(X.view(-1, nx))\n",
    "        \n",
    "        print(yhat.shape, y.shape)\n",
    "        \n",
    "        # Compute cost (averaged across outputs and averaged across examples)\n",
    "        cost = loss(yhat, y)\n",
    "        \n",
    "        # Compute gradients\n",
    "        model.zero_grad()\n",
    "        cost.backward()\n",
    "        \n",
    "        # Update paramters\n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                param -= learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does .view(.) do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10\n",
    "s = 3\n",
    "test_x = torch.randn(m, 1, s, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 3, 3])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.4553,  0.7525, -1.0200],\n",
       "         [ 0.9015, -1.5583,  1.5643],\n",
       "         [ 0.8502, -1.0633,  0.7950]]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4553,  0.7525, -1.0200,  0.9015, -1.5583,  1.5643,  0.8502, -1.0633,\n",
       "         0.7950])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.view(10, s*s)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.7862e-01, -2.4249e+00, -2.4432e+00, -4.8203e-01,  1.7354e+00,\n",
       "           5.2753e-03,  2.0173e-01,  1.8084e-01, -3.4677e-01,  2.2480e+00],\n",
       "         [-1.7831e+00,  1.1494e+00, -4.4402e-01,  1.4853e-01, -7.3438e-01,\n",
       "          -1.0603e-01,  1.1895e+00, -7.7136e-01,  1.6888e-01, -2.0557e-01],\n",
       "         [-1.5728e+00, -2.4993e-01, -1.2287e+00,  5.1157e-01, -1.0426e+00,\n",
       "           5.1899e-02,  5.5372e-01,  9.1097e-01,  1.6721e+00,  3.4615e-01],\n",
       "         [ 2.7168e-01, -1.1921e+00,  2.4070e-03,  7.1422e-01, -1.1906e+00,\n",
       "          -1.0701e-01,  7.6300e-02, -1.0817e+00,  4.9301e-01, -5.6308e-01]],\n",
       "        grad_fn=<SliceBackward>),\n",
       " tensor([4, 6, 8, 3]))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat[:4], y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does `backward()` do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "?cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randn() received an invalid combination of arguments - got (int, use_grad=bool), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.Generator generator, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-1b01c52b668b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: randn() received an invalid combination of arguments - got (int, use_grad=bool), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.Generator generator, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "torch.randn(5, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, requires_grad=True)\n",
    "y = x ** 2\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0622], requires_grad=True)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.1244])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.1244], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2* x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
