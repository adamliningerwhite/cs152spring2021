{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_subset_loader(\n",
    "    train: bool, path: str, c1: int, c2: int\n",
    ") -> Tuple[DataLoader, int]:\n",
    "    \"\"\"Return an MNIST dataloader for the two specified classes.\n",
    "\n",
    "    Args:\n",
    "        train (bool): Should this be a training set or validation set\n",
    "        path (str): The directory in which to store/find the MNIST dataset\n",
    "        c1 (int): a number in [0, 9] denoting a MNIST class/number\n",
    "        c2 (int): a number in [0, 9] denoting a MNIST class/number\n",
    "\n",
    "    Returns:\n",
    "        Tuple[DataLoader, int]: Return a dataloader and its size\n",
    "    \"\"\"\n",
    "\n",
    "    # All inputs must be converted into torch tensors, and the normalization values\n",
    "    # have been precomputed and provided below.\n",
    "    mnist_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)),]\n",
    "    )\n",
    "\n",
    "    dataset = MNIST(root=path, train=train, download=True, transform=mnist_transforms)\n",
    "\n",
    "    # Grab indices for the two classes we care about\n",
    "    idx_classA = [i for i, t in enumerate(dataset.targets) if t == c1]\n",
    "    idx_classB = [i for i, t in enumerate(dataset.targets) if t == c2]\n",
    "\n",
    "    idxs = idx_classA + idx_classB\n",
    "    size = len(idxs)\n",
    "\n",
    "    loader = DataLoader(dataset, sampler=SubsetRandomSampler(idxs), batch_size=size)\n",
    "\n",
    "    return loader, size\n",
    "\n",
    "\n",
    "def get_mnist_data_binary(\n",
    "    path: str, c1: int, c2: int\n",
    ") -> Tuple[DataLoader, int, DataLoader, int]:\n",
    "    \"\"\"Return data loaders for two classes from MNIST.\n",
    "\n",
    "    Args:\n",
    "        path (str): The directory in which to store/find the MNIST dataset\n",
    "        c1 (int): a number in [0, 9] denoting a MNIST class/number\n",
    "        c2 (int): a number in [0, 9] denoting a MNIST class/number\n",
    "\n",
    "    Returns:\n",
    "        Tuple[DataLoader, int, DataLoader, int]: Return a training dataloader the\n",
    "            training set size (and the same for the validation dataset)\n",
    "    \"\"\"\n",
    "\n",
    "    train_loader, train_size = get_mnist_subset_loader(True, path, c1, c2)\n",
    "    valid_loader, valid_size = get_mnist_subset_loader(False, path, c1, c2)\n",
    "\n",
    "    return train_loader, train_size, valid_loader, valid_size\n",
    "\n",
    "\n",
    "def show_image(img, ax=None, title=None):\n",
    "    if not ax:\n",
    "        _, ax = plt.subplots()\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.axis(\"off\")\n",
    "    if title:\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data\"\n",
    "\n",
    "classA = 3\n",
    "classB = 8\n",
    "\n",
    "train_loader, train_size, valid_loader, valid_size = get_mnist_data_binary(\n",
    "    path, classA, classB\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs, train_trgs = next(iter(train_loader))\n",
    "valid_imgs, valid_trgs = next(iter(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network architecture\n",
    "n0 = 28 * 28\n",
    "n1 = 10\n",
    "n2 = 1\n",
    "\n",
    "# Parameters\n",
    "W1 = torch.randn(n1, n0) * 0.01\n",
    "b1 = torch.zeros(n1, 1)\n",
    "W2 = torch.randn(n2, n1) * 0.01\n",
    "b2 = torch.zeros(n2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11982, 1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (335496x28 and 784x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d2eb4024b882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mW1\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mtrain_imgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (335496x28 and 784x10)"
     ]
    }
   ],
   "source": [
    "W1 @ train_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6816, -0.0879,  0.2512,  ...,  0.1073,  0.3881, -0.0224],\n",
       "        [-0.3140, -0.6484, -0.8307,  ..., -0.4685,  0.0343, -0.2737],\n",
       "        [ 0.0028,  0.2823, -0.4793,  ..., -0.3559,  0.3568,  0.1968],\n",
       "        ...,\n",
       "        [ 0.0214,  0.2699, -0.3272,  ..., -0.2781, -0.1322,  0.0824],\n",
       "        [ 0.1696,  0.1552,  0.2495,  ...,  0.3943,  0.1449,  0.0451],\n",
       "        [-0.2817, -0.0100,  0.1982,  ...,  0.3408, -0.1291,  0.3933]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 @ train_imgs.view(-1, n0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass (get the predictions)\n",
    "Z1 = W1 @ train_imgs.view(-1, n0).T + b1\n",
    "A1 = torch.sigmoid(Z1)\n",
    "Z2 = W2 @ A1 + b2\n",
    "A2 = torch.sigmoid(Z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 11982]),\n",
       " torch.Size([10, 11982]),\n",
       " torch.Size([1, 11982]),\n",
       " torch.Size([1, 11982]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z1.shape, A1.shape, Z2.shape, A2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(A0, W1, b1, W2, b2):\n",
    "    Z1 = W1 @ A0 + b1\n",
    "    A1 = torch.sigmoid(Z1)\n",
    "    Z2 = W2 @ A1 + b2\n",
    "    A2 = torch.sigmoid(Z2)\n",
    "    return A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 11982]), torch.Size([11982]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A0 = train_imgs.view(-1, n0).T\n",
    "Y = train_trgs\n",
    "\n",
    "Yhat = forward(A0, W1, b1, W2, b2)\n",
    "Yhat.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(A0, W1, b1, W2, b2):\n",
    "    return forward(A0, W1, b1, W2, b2).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11982])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = prediction(A0, W1, b1, W2, b2)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 8, 8,  ..., 8, 3, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_trgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.zeros_like(train_trgs)\n",
    "Y[train_trgs == classB] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5851), torch.Size([11982]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.sum(), train_trgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4883)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy = (Y - preds).abs().mean()\n",
    "train_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "dZ^{[2]} &= A^{[2]} - Y\\\\\n",
    "dW^{[2]} &= \\frac{1}{m} dZ^{[2]} A^{[1]T}\\\\\n",
    "db^{[2]} &= \\frac{1}{m} \\sum dZ^{[2]}\\\\\n",
    "dZ^{[1]} &= W^{[2]T} dZ^{[2]} A^{[1]} (1 - A^{[1]})\\\\\n",
    "dW^{[1]} &= \\frac{1}{m} dZ^{[1]} A^{[0]T}\\\\\n",
    "db^{[1]} &= \\frac{1}{m} \\sum dZ^{[1]}\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(A0, W1, b1, W2, b2, return_state=False):\n",
    "    Z1 = W1 @ A0 + b1\n",
    "    A1 = torch.sigmoid(Z1)\n",
    "    Z2 = W2 @ A1 + b2\n",
    "    A2 = torch.sigmoid(Z2)\n",
    "    \n",
    "    if return_state:\n",
    "        return A1, A2\n",
    "    else:\n",
    "        return A2\n",
    "\n",
    "def backward(W2, A0, A1, A2, Y):\n",
    "    \"\"\"With sigmoid activations and cross entropy loss.\"\"\"\n",
    "    \n",
    "    m = len(Y)\n",
    "    \n",
    "    dZ2 = (A2 - Y)\n",
    "    dW2 = (1/m) * (dZ2 @ A1.T)\n",
    "    db2 = (1/m) * dZ2.sum(axis=1, keepdims=True)\n",
    "\n",
    "    dZ1 = W2.T @ dZ2 * (A1 * (1 - A1))\n",
    "    dW1 = (1/m) * dZ1 @ A0.T\n",
    "    db1 = (1/m) * dZ1.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    return dW1, db1, dW2, db2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete NN Training on MNIST\n",
    "\n",
    "1. Initialize parameters\n",
    "2. Train parameters\n",
    "    1. Compute predictions\n",
    "    2. Compute gradients\n",
    "    3. Update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49092739820480347\n",
      "0.5090725421905518\n",
      "0.5090725421905518\n",
      "0.6471774578094482\n",
      "0.8649193644523621\n",
      "0.9017137289047241\n",
      "0.9138104915618896\n",
      "0.9279233813285828\n",
      "0.9405242204666138\n"
     ]
    }
   ],
   "source": [
    "# MNIST data\n",
    "path = \"../data\"\n",
    "\n",
    "classA = 3\n",
    "classB = 8\n",
    "\n",
    "train_loader, train_size, valid_loader, valid_size = get_mnist_data_binary(\n",
    "    path, classA, classB\n",
    ")\n",
    "\n",
    "A0 = train_imgs.view(-1, 28*28).T\n",
    "Y = torch.zeros_like(train_trgs.view(1, -1))\n",
    "Y[train_trgs.view(1, -1) == classB] = 1\n",
    "\n",
    "A0_validation = valid_imgs.view(-1, n0).T\n",
    "Y_validation = torch.zeros_like(valid_trgs.view(1, -1))\n",
    "Y_validation[valid_trgs.view(1, -1) == classB] = 1\n",
    "\n",
    "# Optimization hyperparameters\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 8\n",
    "\n",
    "# Neural network architecture and parameters\n",
    "n0 = A0.shape[0]\n",
    "n1 = 10\n",
    "n2 = 1\n",
    "\n",
    "W1 = torch.randn(n1, n0) * 0.01\n",
    "b1 = torch.zeros(n1, 1)\n",
    "W2 = torch.randn(n2, n1) * 0.01\n",
    "b2 = torch.zeros(n2, 1)\n",
    "\n",
    "# Compute initial accuracy\n",
    "valid_preds = prediction(A0_validation, W1, b1, W2, b2)\n",
    "valid_accuracy = 1 - (Y_validation - valid_preds).abs().mean()\n",
    "print(valid_accuracy.item())\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    A1, A2 = forward(A0, W1, b1, W2, b2, return_state=True)\n",
    "    \n",
    "    dW1, db1, dW2, db2 = backward(W2, A0, A1, A2, Y)\n",
    "    \n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "        \n",
    "    valid_preds = prediction(A0_validation, W1, b1, W2, b2)\n",
    "    valid_accuracy = 1 - (Y_validation - valid_preds).abs().mean()\n",
    "    print(valid_accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
