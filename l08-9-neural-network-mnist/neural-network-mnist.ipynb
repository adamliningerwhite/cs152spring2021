{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_subset_loader(\n",
    "    train: bool, path: str, c1: int, c2: int\n",
    ") -> Tuple[DataLoader, int]:\n",
    "    \"\"\"Return an MNIST dataloader for the two specified classes.\n",
    "\n",
    "    Args:\n",
    "        train (bool): Should this be a training set or validation set\n",
    "        path (str): The directory in which to store/find the MNIST dataset\n",
    "        c1 (int): a number in [0, 9] denoting a MNIST class/number\n",
    "        c2 (int): a number in [0, 9] denoting a MNIST class/number\n",
    "\n",
    "    Returns:\n",
    "        Tuple[DataLoader, int]: Return a dataloader and its size\n",
    "    \"\"\"\n",
    "\n",
    "    # All inputs must be converted into torch tensors, and the normalization values\n",
    "    # have been precomputed and provided below.\n",
    "    mnist_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)),]\n",
    "    )\n",
    "\n",
    "    dataset = MNIST(root=path, train=train, download=True, transform=mnist_transforms)\n",
    "\n",
    "    # Grab indices for the two classes we care about\n",
    "    idx_classA = [i for i, t in enumerate(dataset.targets) if t == c1]\n",
    "    idx_classB = [i for i, t in enumerate(dataset.targets) if t == c2]\n",
    "\n",
    "    idxs = idx_classA + idx_classB\n",
    "    size = len(idxs)\n",
    "\n",
    "    loader = DataLoader(dataset, sampler=SubsetRandomSampler(idxs), batch_size=size)\n",
    "\n",
    "    return loader, size\n",
    "\n",
    "\n",
    "def get_mnist_data_binary(\n",
    "    path: str, c1: int, c2: int\n",
    ") -> Tuple[DataLoader, int, DataLoader, int]:\n",
    "    \"\"\"Return data loaders for two classes from MNIST.\n",
    "\n",
    "    Args:\n",
    "        path (str): The directory in which to store/find the MNIST dataset\n",
    "        c1 (int): a number in [0, 9] denoting a MNIST class/number\n",
    "        c2 (int): a number in [0, 9] denoting a MNIST class/number\n",
    "\n",
    "    Returns:\n",
    "        Tuple[DataLoader, int, DataLoader, int]: Return a training dataloader the\n",
    "            training set size (and the same for the validation dataset)\n",
    "    \"\"\"\n",
    "\n",
    "    train_loader, train_size = get_mnist_subset_loader(True, path, c1, c2)\n",
    "    valid_loader, valid_size = get_mnist_subset_loader(False, path, c1, c2)\n",
    "\n",
    "    return train_loader, train_size, valid_loader, valid_size\n",
    "\n",
    "\n",
    "def show_image(img, ax=None, title=None):\n",
    "    if not ax:\n",
    "        _, ax = plt.subplots()\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.axis(\"off\")\n",
    "    if title:\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data\"\n",
    "\n",
    "classA = 3\n",
    "classB = 8\n",
    "\n",
    "train_loader, train_size, valid_loader, valid_size = get_mnist_data_binary(\n",
    "    path, classA, classB\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs, train_trgs = next(iter(train_loader))\n",
    "valid_imgs, valid_trgs = next(iter(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network architecture\n",
    "n0 = 28 * 28\n",
    "n1 = 10\n",
    "n2 = 1\n",
    "\n",
    "# Parameters\n",
    "W1 = torch.randn(n1, n0) * 0.01\n",
    "b1 = torch.zeros(n1, 1)\n",
    "W2 = torch.randn(n2, n1) * 0.01\n",
    "b2 = torch.zeros(n2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 @ train_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 @ train_imgs.view(-1, n0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass (get the predictions)\n",
    "Z1 = W1 @ train_imgs.view(-1, n0).T + b1\n",
    "A1 = torch.sigmoid(Z1)\n",
    "Z2 = W2 @ A1 + b2\n",
    "A2 = torch.sigmoid(Z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1.shape, A1.shape, Z2.shape, A2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(A0, W1, b1, W2, b2):\n",
    "    Z1 = W1 @ A0 + b1\n",
    "    A1 = torch.sigmoid(Z1)\n",
    "    Z2 = W2 @ A1 + b2\n",
    "    A2 = torch.sigmoid(Z2)\n",
    "    return A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A0 = train_imgs.view(-1, n0).T\n",
    "Y = train_trgs\n",
    "\n",
    "Yhat = forward(A0, W1, b1, W2, b2)\n",
    "Yhat.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(A0, W1, b1, W2, b2):\n",
    "    return forward(A0, W1, b1, W2, b2).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = prediction(A0, W1, b1, W2, b2)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.zeros_like(train_trgs)\n",
    "Y[train_trgs == classB] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.sum(), train_trgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = (Y - preds).abs().mean()\n",
    "train_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "dZ^{[2]} &= A^{[2]} - Y\\\\\n",
    "dW^{[2]} &= \\frac{1}{m} dZ^{[2]} A^{[1]T}\\\\\n",
    "db^{[2]} &= \\frac{1}{m} \\sum dZ^{[2]}\\\\\n",
    "dZ^{[1]} &= W^{[2]T} dZ^{[2]} A^{[1]} (1 - A^{[1]})\\\\\n",
    "dW^{[1]} &= \\frac{1}{m} dZ^{[1]} A^{[0]T}\\\\\n",
    "db^{[1]} &= \\frac{1}{m} \\sum dZ^{[1]}\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(A0, W1, b1, W2, b2, return_state=False):\n",
    "    Z1 = W1 @ A0 + b1\n",
    "    A1 = torch.sigmoid(Z1)\n",
    "    Z2 = W2 @ A1 + b2\n",
    "    A2 = torch.sigmoid(Z2)\n",
    "    \n",
    "    if return_state:\n",
    "        return A1, A2\n",
    "    else:\n",
    "        return A2\n",
    "\n",
    "def backward(W2, A0, A1, A2, Y):\n",
    "    \"\"\"With sigmoid activations and cross entropy loss.\"\"\"\n",
    "    \n",
    "    m = len(Y)\n",
    "    \n",
    "    dZ2 = (A2 - Y)\n",
    "    dW2 = (1/m) * (dZ2 @ A1.T)\n",
    "    db2 = (1/m) * dZ2.sum(axis=1, keepdims=True)\n",
    "\n",
    "    dZ1 = W2.T @ dZ2 * (A1 * (1 - A1))\n",
    "    dW1 = (1/m) * dZ1 @ A0.T\n",
    "    db1 = (1/m) * dZ1.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    return dW1, db1, dW2, db2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete NN Training on MNIST\n",
    "\n",
    "1. Initialize parameters\n",
    "2. Train parameters\n",
    "    1. Compute predictions\n",
    "    2. Compute gradients\n",
    "    3. Update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data\n",
    "path = \"../data\"\n",
    "\n",
    "classA = 3\n",
    "classB = 8\n",
    "\n",
    "train_loader, train_size, valid_loader, valid_size = get_mnist_data_binary(\n",
    "    path, classA, classB\n",
    ")\n",
    "\n",
    "A0 = train_imgs.view(-1, 28*28).T\n",
    "Y = torch.zeros_like(train_trgs.view(1, -1))\n",
    "Y[train_trgs.view(1, -1) == classB] = 1\n",
    "\n",
    "A0_validation = valid_imgs.view(-1, n0).T\n",
    "Y_validation = torch.zeros_like(valid_trgs.view(1, -1))\n",
    "Y_validation[valid_trgs.view(1, -1) == classB] = 1\n",
    "\n",
    "# Optimization hyperparameters\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 8\n",
    "\n",
    "# Neural network architecture and parameters\n",
    "n0 = A0.shape[0]\n",
    "n1 = 10\n",
    "n2 = 1\n",
    "\n",
    "W1 = torch.randn(n1, n0) * 0.01\n",
    "b1 = torch.zeros(n1, 1)\n",
    "W2 = torch.randn(n2, n1) * 0.01\n",
    "b2 = torch.zeros(n2, 1)\n",
    "\n",
    "# Compute initial accuracy\n",
    "valid_preds = prediction(A0_validation, W1, b1, W2, b2)\n",
    "valid_accuracy = 1 - (Y_validation - valid_preds).abs().mean()\n",
    "print(valid_accuracy.item())\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    A1, A2 = forward(A0, W1, b1, W2, b2, return_state=True)\n",
    "    \n",
    "    dW1, db1, dW2, db2 = backward(W2, A0, A1, A2, Y)\n",
    "    \n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "        \n",
    "    valid_preds = prediction(A0_validation, W1, b1, W2, b2)\n",
    "    valid_accuracy = 1 - (Y_validation - valid_preds).abs().mean()\n",
    "    print(valid_accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
