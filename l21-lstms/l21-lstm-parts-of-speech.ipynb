{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting parts of speech with an LSTM\n",
    "\n",
    "Let's preview the end result. We want to take a sentence and output the part of speech for each word in that sentence. Something like this:\n",
    "\n",
    "**Code**\n",
    "\n",
    "```python\n",
    "new_sentence = \"I is a teeth\"\n",
    "\n",
    "...\n",
    "\n",
    "predictions = model(new_sentence)\n",
    "\n",
    "...\n",
    "```\n",
    "\n",
    "**Output**\n",
    "\n",
    "```text\n",
    "I     => Noun\n",
    "is    => Verv\n",
    "a     => Determiner\n",
    "teeth => Noun\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from random import shuffle\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "Our dataset includes a number of labeled sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could use a larger dataset...\n",
    "# Please add sentences here: https://docs.google.com/spreadsheets/d/1HJmlehaYhGWclDo1t0k6i1VHxN15zr8ZmJj7Rf_VEaI/edit#gid=865244837\n",
    "# You can use this to double check yourself: https://parts-of-speech.info/\n",
    "\n",
    "# Tags:\n",
    "#  D - determiner\n",
    "#  N - noun\n",
    "#  V - verb\n",
    "dataset = [\n",
    "    (\"The dog ate the apple\".lower().split(), [\"D\", \"N\", \"V\", \"D\", \"N\"]),\n",
    "    (\"Everybody read that book\".lower().split(), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (\"Trapp is sleeping\".lower().split(), [\"N\", \"V\", \"V\"]),\n",
    "    (\"Everybody ate the apple\".lower().split(), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (\"Cats are good\".lower().split(), [\"N\", \"V\", \"D\"]),\n",
    "    (\n",
    "        \"Dogs are not as good as cats\".lower().split(),\n",
    "        [\"N\", \"V\", \"D\", \"D\", \"D\", \"D\", \"N\"],\n",
    "    ),\n",
    "    (\"Dogs eat dog food\".lower().split(), [\"N\", \"V\", \"N\", \"N\"]),\n",
    "    (\"Watermelon is the best food\".lower().split(), [\"N\", \"V\", \"D\", \"D\", \"N\"]),\n",
    "    (\"I want a milkshake right now\".lower().split(), [\"N\", \"V\", \"D\", \"N\", \"D\", \"D\"]),\n",
    "    (\"I have too much homework\".lower().split(), [\"N\", \"V\", \"D\", \"D\", \"N\"]),\n",
    "    (\"Zoom won't work\".lower().split(), [\"N\", \"D\", \"V\"]),\n",
    "    (\"Pie also sounds good\".lower().split(), [\"N\", \"D\", \"V\", \"D\"]),\n",
    "    (\n",
    "        \"The college is having the department fair this Friday\".lower().split(),\n",
    "        [\"D\", \"N\", \"V\", \"V\", \"D\", \"N\", \"N\", \"D\", \"N\"],\n",
    "    ),\n",
    "    (\"Research interests span many areas\".lower().split(), [\"N\", \"N\", \"V\", \"D\", \"N\"]),\n",
    "    (\"Alex is finishing his Ph.D\".lower().split(), [\"N\", \"V\", \"V\", \"D\", \"N\"]),\n",
    "    (\"She is the author\".lower().split(), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (\n",
    "        \"It is almost the end of the semester\".lower().split(),\n",
    "        [\"N\", \"V\", \"D\", \"D\", \"N\", \"D\", \"D\", \"N\"],\n",
    "    ),\n",
    "    (\"Blue is a color\".lower().split(), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (\"They wrote a book\".lower().split(), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (\"The syrup covers the pancake\".lower().split(), [\"D\", \"N\", \"V\", \"D\", \"N\"]),\n",
    "    (\"Harrison has these teeth\".lower().split(), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (\"The numbers are fractions\".lower().split(), [\"D\", \"N\", \"V\", \"N\"]),\n",
    "    (\"Yesterday happened\".lower().split(), [\"N\", \"V\"]),\n",
    "    (\"Caramel is sweet\".lower().split(), [\"N\", \"V\", \"D\"]),\n",
    "    (\"Computers use electricity\".lower().split(), [\"N\", \"V\", \"N\"]),\n",
    "    (\"Gold is a valuable thing\".lower().split(), [\"N\", \"V\", \"D\", \"D\", \"N\"]),\n",
    "    (\"This extension cord helps\".lower().split(), [\"D\", \"D\", \"N\", \"V\"]),\n",
    "    (\"It works on my machine\".lower().split(), [\"N\", \"V\", \"D\", \"D\", \"N\"]),\n",
    "    (\"We have the words\".lower().split(), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (\"Trapp is a dog\".lower().split(), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (\"This is a computer\".lower().split(), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for use as NN input\n",
    "\n",
    "We can't pass a list of plain text words and tags to a NN. We need to convert them to a more appropriate format.\n",
    "\n",
    "We'll start by creating a unique index for each word and tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indices = {}\n",
    "total_words = 0\n",
    "\n",
    "tag_indices = {}\n",
    "tag_list = []\n",
    "total_tags = 0\n",
    "\n",
    "for sentence, tags in dataset:\n",
    "    assert len(sentence) == len(tags)\n",
    "    total_words += len(sentence)\n",
    "    for word in sentence:\n",
    "        if word not in word_indices:\n",
    "            word_indices[word] = len(word_indices)\n",
    "\n",
    "    total_tags += len(tags)\n",
    "    for tag in tags:\n",
    "        if tag not in tag_indices:\n",
    "            tag_indices[tag] = len(tag_indices)\n",
    "            tag_list.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Vocabulary Indices\n",
      "-------------------------------\n",
      "           the =>  0\n",
      "           dog =>  1\n",
      "           ate =>  2\n",
      "         apple =>  3\n",
      "     everybody =>  4\n",
      "          read =>  5\n",
      "          that =>  6\n",
      "          book =>  7\n",
      "         trapp =>  8\n",
      "            is =>  9\n",
      "      sleeping => 10\n",
      "          cats => 11\n",
      "           are => 12\n",
      "          good => 13\n",
      "          dogs => 14\n",
      "           not => 15\n",
      "            as => 16\n",
      "           eat => 17\n",
      "          food => 18\n",
      "    watermelon => 19\n",
      "          best => 20\n",
      "             i => 21\n",
      "          want => 22\n",
      "             a => 23\n",
      "     milkshake => 24\n",
      "         right => 25\n",
      "           now => 26\n",
      "          have => 27\n",
      "           too => 28\n",
      "          much => 29\n",
      "      homework => 30\n",
      "          zoom => 31\n",
      "         won't => 32\n",
      "          work => 33\n",
      "           pie => 34\n",
      "          also => 35\n",
      "        sounds => 36\n",
      "       college => 37\n",
      "        having => 38\n",
      "    department => 39\n",
      "          fair => 40\n",
      "          this => 41\n",
      "        friday => 42\n",
      "      research => 43\n",
      "     interests => 44\n",
      "          span => 45\n",
      "          many => 46\n",
      "         areas => 47\n",
      "          alex => 48\n",
      "     finishing => 49\n",
      "           his => 50\n",
      "          ph.d => 51\n",
      "           she => 52\n",
      "        author => 53\n",
      "            it => 54\n",
      "        almost => 55\n",
      "           end => 56\n",
      "            of => 57\n",
      "      semester => 58\n",
      "          blue => 59\n",
      "         color => 60\n",
      "          they => 61\n",
      "         wrote => 62\n",
      "         syrup => 63\n",
      "        covers => 64\n",
      "       pancake => 65\n",
      "      harrison => 66\n",
      "           has => 67\n",
      "         these => 68\n",
      "         teeth => 69\n",
      "       numbers => 70\n",
      "     fractions => 71\n",
      "     yesterday => 72\n",
      "      happened => 73\n",
      "       caramel => 74\n",
      "         sweet => 75\n",
      "     computers => 76\n",
      "           use => 77\n",
      "   electricity => 78\n",
      "          gold => 79\n",
      "      valuable => 80\n",
      "         thing => 81\n",
      "     extension => 82\n",
      "          cord => 83\n",
      "         helps => 84\n",
      "         works => 85\n",
      "            on => 86\n",
      "            my => 87\n",
      "       machine => 88\n",
      "            we => 89\n",
      "         words => 90\n",
      "      computer => 91\n",
      "\n",
      "Total number of words: 139\n",
      "Number of unique words: 92\n"
     ]
    }
   ],
   "source": [
    "print(\"       Vocabulary Indices\")\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "for word, index in word_indices.items():\n",
    "    print(f\"{word:>14} => {index:>2}\")\n",
    "\n",
    "print(\"\\nTotal number of words:\", total_words)\n",
    "print(\"Number of unique words:\", len(word_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag Indices\n",
      "-----------\n",
      "  D => 0\n",
      "  N => 1\n",
      "  V => 2\n",
      "\n",
      "Total number of tags: 139\n",
      "Number of unique tags: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Tag Indices\")\n",
    "print(\"-----------\")\n",
    "\n",
    "for tag, index in tag_indices.items():\n",
    "    print(f\"  {tag} => {index}\")\n",
    "\n",
    "print(\"\\nTotal number of tags:\", total_tags)\n",
    "print(\"Number of unique tags:\", len(tag_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Letting the NN parameterize words\n",
    "\n",
    "Once we have a unique identifier for each word, it is useful to start our NN with an [embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding) layer. This layer converts an index into a vector of values.\n",
    "\n",
    "You can think of each value as indicating something about the word. For example, maybe the first value indicates how much a word conveys happiness vs sadness. Of course, the NN can learn any attributes and it is not limited to thinks like happy/sad, masculine/feminine, etc.\n",
    "\n",
    "**Creating an embedding layer**. An embedding layer is created by telling it the size of the vocabulary (the number of words) and an embedding dimension (how many values to use to represent a word).\n",
    "\n",
    "**Embedding layer input and output**. An embedding layer takes an index and return a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_indices_tensor(\n",
    "    input_sequence: List[str], indices_dict: Dict[str, int]\n",
    ") -> torch.tensor:\n",
    "    \"\"\"Convert a list of indices into a torch.tensor\"\"\"\n",
    "    indices = [indices_dict[w] for w in input_sequence]\n",
    "    return torch.tensor(indices, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embedding layer output contains 'embedding_size' values for each word\n",
      "torch.Size([2, 6])\n",
      "tensor([[-0.3101, -2.0614,  0.6138,  0.6309, -2.1374, -0.3048],\n",
      "        [-1.9204,  1.1053, -0.4639, -0.1313,  0.1203, -0.5256]])\n"
     ]
    }
   ],
   "source": [
    "vocabulary_count = len(word_indices)  # Depends on the dataset\n",
    "embedding_size = 6  # Hyperparameter\n",
    "\n",
    "example_sentence = [\"dog\", \"ate\"]\n",
    "example_sentence_indices = convert_to_indices_tensor(example_sentence, word_indices)\n",
    "\n",
    "embedding_layer = nn.Embedding(vocabulary_count, embedding_size)\n",
    "embeddings = embedding_layer(example_sentence_indices)\n",
    "\n",
    "print(\"The embedding layer output contains 'embedding_size' values for each word\")\n",
    "print(embeddings.shape)\n",
    "print(embeddings.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding an LSTM layer\n",
    "\n",
    "The [LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM) layer is in charge of processing embeddings such that the network can output the correct classification. Since this is a recurrent layer, it will take into account past words when it creates an output for the current word.\n",
    "\n",
    "**Creating an LSTM layer**. To create an LSTM you need to tell it the size of its input (the size of an embedding) and the size of its internal cell state.\n",
    "\n",
    "**LSTM layer input and output**. An LSTM takes an embedding (and optionally an initial hidden and cell state) and outputs a value for each word as well as the current hidden and cell state).\n",
    "\n",
    "If you read the linked LSTM documentation you will see that it requires input in this format: (seq_len, batch, input_size)\n",
    "\n",
    "As you can see above, our embedding layer outputs something that is (seq_len, input_size). So, we need to add a dimension in the middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 6])\n",
      "tensor([[[-0.3101, -2.0614,  0.6138,  0.6309, -2.1374, -0.3048]],\n",
      "\n",
      "        [[-1.9204,  1.1053, -0.4639, -0.1313,  0.1203, -0.5256]]])\n"
     ]
    }
   ],
   "source": [
    "unflatten_layer = nn.Unflatten(1, (1, embedding_size))\n",
    "reshaped_embeddings = unflatten_layer(embeddings)\n",
    "print(reshaped_embeddings.shape)\n",
    "print(reshaped_embeddings.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 4])\n",
      "tensor([[[ 0.2159,  0.0386, -0.2349,  0.0862]],\n",
      "\n",
      "        [[ 0.2722, -0.0091, -0.4316,  0.0084]]])\n"
     ]
    }
   ],
   "source": [
    "lstm_state_size = 4  # Hyperparamter\n",
    "\n",
    "lstm_layer = nn.LSTM(embedding_size, lstm_state_size)\n",
    "\n",
    "# We can ignore the hidden and cell state outputs\n",
    "lstm_output, (h_T, C_T) = lstm_layer(reshaped_embeddings)\n",
    "print(lstm_output.shape)\n",
    "print(lstm_output.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiying the LSTM output\n",
    "\n",
    "We can now add a fully connected, [linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) layer to our NN to learn the correct part of speech (classification).\n",
    "\n",
    "**Creating a linear layer**. We create a linear layer by specifying the shape of the input into the layer and the number of neurons in the linear layer.\n",
    "\n",
    "**Linear layer input and output**. The input is expected to be (input_size, output_size) and the output will be the output of each neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "tensor([[ 0.2159,  0.0386, -0.2349,  0.0862],\n",
      "        [ 0.2722, -0.0091, -0.4316,  0.0084]])\n"
     ]
    }
   ],
   "source": [
    "flatten_layer = nn.Flatten()\n",
    "reshaped_lstm_output = flatten_layer(lstm_output)\n",
    "print(reshaped_lstm_output.shape)\n",
    "print(reshaped_lstm_output.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[-0.2860,  0.6836,  0.0550],\n",
      "        [-0.2402,  0.7779,  0.0714]])\n"
     ]
    }
   ],
   "source": [
    "tag_count = len(tag_list)\n",
    "\n",
    "linear = nn.Linear(lstm_state_size, tag_count)\n",
    "linear_out = linear(reshaped_lstm_output)\n",
    "print(linear_out.shape)\n",
    "print(linear_out.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "valid_percent = 0.2\n",
    "\n",
    "embedding_size = 6\n",
    "lstm_state_size = 6\n",
    "\n",
    "learning_rate = 0.1\n",
    "num_epochs = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 25)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset values\n",
    "N = len(dataset)\n",
    "vocab_count = len(word_indices)\n",
    "tag_count = len(tag_indices)\n",
    "\n",
    "# Shuffle the data so that we can split the dataset randomly\n",
    "shuffle(dataset)\n",
    "\n",
    "split_point = int(N * valid_percent)\n",
    "valid_dataset = dataset[:split_point]\n",
    "train_dataset = dataset[split_point:]\n",
    "\n",
    "len(valid_dataset), len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the LSTM model\n",
    "\n",
    "If you followed the steps above, you might notice that there are some LSTM outputs that we need to ignore. One way to do that is to create a new LSTM layer that simply ignores the unneeded output. That is what `FlatLSTM` does below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlatLSTM(nn.Module):\n",
    "    \"\"\"An LSTM layer that ignores the current hidden and cell states.\"\"\"\n",
    "    def __init__(self, in_dim, state_dim):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(in_dim, state_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_output, _ = self.lstm(x)\n",
    "        return lstm_output\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Embedding(vocab_count, embedding_size),\n",
    "    nn.Unflatten(1, (1, embedding_size)),\n",
    "    FlatLSTM(embedding_size, lstm_state_size),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(lstm_state_size, tag_count),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(dataset):\n",
    "    \"\"\"A helper function for computing accuracy on the given dataset.\"\"\"\n",
    "    total_words = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sentence, tags in dataset:\n",
    "            sentence_indices = convert_to_indices_tensor(sentence, word_indices)\n",
    "            tag_scores = model(sentence_indices)\n",
    "            predictions = tag_scores.argmax(dim=1)\n",
    "            total_words += len(sentence)\n",
    "            total_correct += sum(t == tag_list[p] for t, p in zip(tags, predictions))\n",
    "\n",
    "    return total_correct / total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy before training : 25.00%\n",
      "Validation accuracy after training  : 54.17%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "accuracy = compute_accuracy(valid_dataset)\n",
    "print(f\"Validation accuracy before training : {accuracy * 100:.2f}%\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Shuffle the data for each epoch (stochastic gradient descent)\n",
    "    shuffle(train_dataset)\n",
    "    \n",
    "    for sentence, tags in train_dataset:\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        sentence = convert_to_indices_tensor(sentence, word_indices)\n",
    "        tags = convert_to_indices_tensor(tags, tag_indices)\n",
    "        \n",
    "        tag_scores = model(sentence)\n",
    "        \n",
    "        loss = criterion(tag_scores, tags)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "accuracy = compute_accuracy(valid_dataset)\n",
    "print(f\"Validation accuracy after training  : {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining results\n",
    "\n",
    "Here we look at all words that are misclassified by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mis-predictions after training on entire dataset\n",
      "     Word      | True Tag | Prediction\n",
      "--------------------------------------\n",
      "      research |     N    |    D\n",
      "          span |     V    |    N\n",
      "          many |     D    |    V\n",
      "         areas |     N    |    V\n",
      "           has |     V    |    N\n",
      "         these |     D    |    N\n",
      "         teeth |     N    |    D\n",
      "         sweet |     D    |    V\n",
      "     fractions |     N    |    V\n",
      "            we |     N    |    V\n",
      "         words |     N    |    D\n",
      "          this |     D    |    N\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMis-predictions after training on entire dataset\")\n",
    "header = \"Word\".center(14) + \" | True Tag | Prediction\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sentence, tags in dataset:\n",
    "        sentence_indices = convert_to_indices_tensor(sentence, word_indices)\n",
    "        tag_scores = model(sentence_indices)\n",
    "        predictions = tag_scores.argmax(dim=1)\n",
    "        for word, tag, pred in zip(sentence, tags, predictions):\n",
    "            if tag != tag_list[pred]:\n",
    "                print(f\"{word:>14} |     {tag}    |    {tag_list[pred]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I => N\n",
      "is => V\n",
      "a => D\n",
      "teeth => N\n"
     ]
    }
   ],
   "source": [
    "new_sentence = \"I is a teeth\"\n",
    "\n",
    "# Convert sentence to lowercase words\n",
    "sentence = new_sentence.lower().split()\n",
    "\n",
    "# Check that each word is in our vocabulary\n",
    "for word in sentence:\n",
    "    assert word in word_indices\n",
    "\n",
    "# Convert input to a tensor\n",
    "sentence = convert_to_indices_tensor(sentence, word_indices)\n",
    "\n",
    "# Compute prediction\n",
    "predictions = model(sentence)\n",
    "predictions = predictions.argmax(dim=1)\n",
    "\n",
    "# Print results\n",
    "for word, tag in zip(new_sentence.split(), predictions):\n",
    "    print(word, \"=>\", tag_list[tag.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
